{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # i was getting some warnings about missing glyphs in font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hour_of_week_and_year(row):\n",
    "    import pytz\n",
    "    offset = {\n",
    "        \"N. Virginia\":  \"EST\",\n",
    "        \"Ireland\":  \"GMT\",\n",
    "        \"Global\":  \"GMT\",\n",
    "        \"N. California\":  \"US/Pacific\",\n",
    "        \"Sydney\":  \"Australia/Sydney\",\n",
    "        \"Oregon\":  \"US/Pacific\",\n",
    "        \"GovCloud\":  \"US/Pacific\",\n",
    "        \"London\":  \"Europe/London\",\n",
    "        \"Ohio\":  \"EST\",\n",
    "        \"Sao Paulo\":  \"America/Sao_Paulo\",\n",
    "        \"Tokyo\":  \"Asia/Tokyo\",\n",
    "        \"Mumbai\":  \"Asia/Kolkata\",\n",
    "        \"Singapore\":  \"Asia/Singapore\",\n",
    "        \"Seoul\":  \"Asia/Seoul\",\n",
    "        \"Frankfurt\":  \"Europe/Berlin\",\n",
    "        \"Paris\":  \"Europe/Paris\",\n",
    "        \"US-West\":  \"US/Pacific\",\n",
    "        \"East US\":  \"EST\",\n",
    "        \"global\":  \"GMT\",\n",
    "        \"RCA – Resources using IPv4 addressing – West and South India\":  \"Asia/Kolkata\",\n",
    "        \"West Europe\":  \"Europe/Amsterdam\",\n",
    "        \"West US\":  \"US/Pacific\",\n",
    "        \"Australia East\":  \"Australia/Sydney\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"North Central US\":  \"America/Chicago\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"North Europe and West Europe\":  \"Europe/Berlin\",\n",
    "        \"UK West\":  \"Europe/London\",\n",
    "        \"South Central US\":  \"US/Central\",\n",
    "        \"RCA – Storage – West US\":  \"US/Pacific\",\n",
    "        \"West India and South India\":  \"Asia/Kolkata\",\n",
    "        \"Latency between North Europe and North America\":  \"GMT\",\n",
    "        \"France Central\":  \"Europe/Paris\",\n",
    "        \"East Asia\":  \"Asia/Hong_Kong\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"Australia Southeast\":  \"Australia/Melbourne\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"Korea South\":  \"Asia/Seoul\",\n",
    "        \"Southeast Asia\":  \"Asia/Singapore\",\n",
    "        \"West Europe and North Europe\":  \"Europe/Berlin\",\n",
    "        \"Latency and Slow I/O issues in East US\":  \"EST\",\n",
    "        \"Networking in West US\":  \"US/Pacific\",\n",
    "        \"UK South\":  \"Europe/London\",\n",
    "        \"West US 2\":  \"US/Central\",\n",
    "        \"East US and West US\":  \"US/Central\",\n",
    "        \"UK South and UK West\":  \"Europe/London\",\n",
    "        \"North Europe\":  \"Europe/Berlin\",\n",
    "        \"UK South/UK West\":  \"Europe/London\",\n",
    "        \"West Central US\":  \"US/Central\",\n",
    "        \"West Europe | Mitigated\":  \"Europe/Amsterdam\",\n",
    "        \"Data Processing in East US\":  \"EST\",\n",
    "        \"Australia East/Southeast\":  \"Australia/Melbourne\",\n",
    "        \"Canada Central\":  \"Canada/Central\",\n",
    "        \"Japan East\":  \"Japan\",\n",
    "        \"Multiple Azure Services impacted in West Europe\":  \"Europe/Amsterdam\",\n",
    "        \"Service availability issue in North Europe\":  \"Europe/Berlin\",\n",
    "        \"Service Availability Issue in North Europe\":  \"Europe/Berlin\",\n",
    "        \"South East Asia\":  \"Asia/Singapore\",\n",
    "        \"us-central1\": \"US/Central\", # Iowa\n",
    "        \"us-east4\": \"US/Eastern\", # Northern Virginia\n",
    "        \"us-east1\": \"US/Eastern\", # South Carolina\n",
    "        \"europe-west2\": \"Europe/London\", # London\n",
    "        \"europe-west1\": \"Europe/Brussels\", # St Ghislain\n",
    "        \"europe-west4\": \"Europe/Amsterdam\", # Eemshaven\n",
    "        \"asia-southeast1\": \"Asia/Singapore\", # Jurong West\n",
    "        \"europe-north1\": \"Europe/Helsinki\", # Hamina\n",
    "        \"us-west1\": \"US/Pacific\", # Oregon\n",
    "        \"Canada\": \"Canada/Eastern\" # GCP region in Montreal\n",
    "    }\n",
    "    timezone_diff = pytz.timezone(offset[row['location']])\n",
    "    localized_event_start_time = row['event_start_time'].tz_convert(timezone_diff)\n",
    "    weekday_int = localized_event_start_time.dayofweek\n",
    "    hour = localized_event_start_time.hour\n",
    "    row['hour_of_week'] = (weekday_int)*24+hour\n",
    "    row['year'] = localized_event_start_time.year\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_id', 'service_name', 'location', 'status', 'event_start_time',\n",
      "       'event_end_time', 'description', 'vendor', 'first_notification',\n",
      "       'last_notification', 'monitor', 'org_type', 'half_desc'],\n",
      "      dtype='object')\n",
      "Index(['services', 'severity', 'range', 'users', 'cause', 'duration',\n",
      "       'affected'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_parquet(\"../data/classified.parquet\")\n",
    "original = pd.read_parquet(\"../data/outages.parquet\")\n",
    "print(original.columns)\n",
    "print(df.columns)\n",
    "dfj = df.join(original)\n",
    "dfj = dfj[dfj.description.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed:\n",
      "- Azure: 137\n",
      "- GCP: 136\n",
      "- AWS: 127\n"
     ]
    }
   ],
   "source": [
    "def deduplicate(df):\n",
    "    dfnew = (df.sort_values('event_end_time', ascending=False) # Put the rows with the highest end time (ie longest duration) first\n",
    "             .drop_duplicates(['service_name', 'location', 'event_start_time']) # Dedupe based on these columns\n",
    "             .sort_index()) # Sort back to default\n",
    "    \n",
    "    removed_vendors = df.loc[df.index.difference(dfnew.index)].vendor.value_counts()\n",
    "    print(\"Removed:\")\n",
    "    for vd, cnt in removed_vendors.iteritems():\n",
    "        print(f'- {vd}: {cnt}')\n",
    "    \n",
    "    return dfnew\n",
    "\n",
    "dfj = deduplicate(dfj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj['duration_min'] = (dfj.event_end_time - dfj.event_start_time)/60.0\n",
    "dfj[\"event_start_time\"] = pd.to_datetime(dfj[\"event_start_time\"], unit=\"s\", utc=True)\n",
    "dfj[\"event_end_time\"] = pd.to_datetime(dfj[\"event_end_time\"], unit=\"s\", utc=True)\n",
    "dfj = dfj.apply(add_hour_of_week_and_year, axis='columns')\n",
    "dfj.drop(labels=['event_start_time', 'event_end_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed events before 2018:\n",
      "- AWS: 184\n",
      "- GCP: 73\n",
      "- Azure: 17\n"
     ]
    }
   ],
   "source": [
    "removed_events_by_vendor = dfj[dfj.year < 2018].vendor.value_counts()\n",
    "print(\"Removed events before 2018:\")\n",
    "for vd, cnt in removed_events_by_vendor.iteritems():\n",
    "    print(f'- {vd}: {cnt}')\n",
    "\n",
    "dfj = dfj[dfj.year >= 2018].drop(['year'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_emptys(cell):\n",
    "    from numpy import ndarray\n",
    "    if type(cell) == ndarray and len(cell) == 0:\n",
    "        return ['not provided']\n",
    "    elif type(cell) == str and not bool(cell):\n",
    "        return 'not provided'\n",
    "    \n",
    "    return cell\n",
    "\n",
    "dfj = dfj.applymap(clean_emptys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broaden_causes(cell):\n",
    "    superclasses = {'code error': {'code error', 'backend inefficiency'},\n",
    "                    'maintenance side effect': {'maintenance side effect'},\n",
    "                    'configuration error': {'configuration error', 'deployment task'},\n",
    "                    'network': {'internal api issue', 'internal network issue'},\n",
    "                    'external': {'environmental conditions', 'shock event', 'third party'},\n",
    "                    'load': {'increased load'},\n",
    "                    'unknown': {'not provided'},\n",
    "                    'unit': {'unhealthy unit'}}\n",
    "    for k,v in superclasses.items():\n",
    "        if bool(cell in v):\n",
    "            return k\n",
    "    raise Exception(f'\"{cell}\" not in superclasses!')\n",
    "\n",
    "dfj['cause_broader'] = dfj.cause.map(broaden_causes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['services', 'severity', 'range', 'users', 'cause', 'duration',\n",
       "       'affected', 'service_id', 'service_name', 'location', 'status',\n",
       "       'description', 'vendor', 'first_notification', 'last_notification',\n",
       "       'monitor', 'org_type', 'half_desc', 'duration_min', 'hour_of_week',\n",
       "       'cause_broader'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "services\n",
      "{'multiple', 'not provided', 'one'} \n",
      "\n",
      "severity\n",
      "{'visual', 'degraded performance', 'not provided', 'unavailable'} \n",
      "\n",
      "range\n",
      "{'multiple regions', 'single availability zone', 'not provided', 'single region'} \n",
      "\n",
      "users\n",
      "{'all', 'some', 'not provided'} \n",
      "\n",
      "cause\n",
      "{'internal api issue', 'not provided', 'internal network issue', 'increased load', 'deployment task', 'backend inefficiency', 'third party', 'maintenance side effect', 'configuration error', 'shock event', 'code error', 'unhealthy unit', 'environmental conditions'} \n",
      "\n",
      "duration\n",
      "{'intermittent', 'continuous', 'not provided'} \n",
      "\n",
      "affected\n",
      "{'internal network', 'not provided', 'external requests (apis)', 'external network/connectivity', 'internal communication interfaces', 'nodes/devices/instances', 'certificates/licenses', 'user interface', 'processing backend', 'storage'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(c)\n",
    "    if type(dfj[c].iloc[0]) == str:\n",
    "        print(set(dfj[c].tolist()), '\\n')\n",
    "    else:\n",
    "        print({x for sublist in dfj[c].tolist() for x in sublist}, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj = dfj.astype({'affected': 'object',\n",
    "                  'cause': 'str',\n",
    "                  'cause_broader': 'str',\n",
    "                  'description': 'str',\n",
    "                  'duration': 'str',\n",
    "                  'duration_min': 'float',\n",
    "                  'first_notification': 'Int64',\n",
    "                  'half_desc': 'str',\n",
    "                  'hour_of_week': 'Int32',\n",
    "                  'last_notification': 'Int64',\n",
    "                  'location': 'str',\n",
    "                  'monitor': 'str',\n",
    "                  'org_type': 'str',\n",
    "                  'range': 'str',\n",
    "                  'service_id': 'str',\n",
    "                  'service_name': 'str',\n",
    "                  'services': 'str',\n",
    "                  'severity': 'object',\n",
    "                  'status': 'float',\n",
    "                  'users': 'str'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of outages in a single AWS availability zone: 14\n"
     ]
    }
   ],
   "source": [
    "print(f'Amount of outages in a single AWS availability zone: {len(dfj[dfj.range == \"single availability zone\"])}')\n",
    "\n",
    "dfj.range = dfj.range.map(lambda x: 'single region' if x == 'single availability zone' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final counts for all vendors:\n",
      "- AWS: 144\n",
      "- GCP: 139\n",
      "- Azure: 128\n"
     ]
    }
   ],
   "source": [
    "print(\"Final counts for all vendors:\")\n",
    "for vd, cnt in dfj.vendor.value_counts().iteritems():\n",
    "    print(f'- {vd}: {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj = dfj.drop(['service_id', 'service_name', 'status', 'first_notification', 'last_notification', 'monitor', 'org_type', 'half_desc'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj.to_parquet(\"../data/preprocessed.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
