{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Done classifying, should not longer be necessary\n",
    "# %run '../scripts/joplin-to-parquet.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # i was getting some warnings about missing glyphs in font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hour_of_week(row):\n",
    "    import pytz\n",
    "    offset = {\n",
    "        \"N. Virginia\":  \"EST\",\n",
    "        \"Ireland\":  \"GMT\",\n",
    "        \"Global\":  \"GMT\",\n",
    "        \"N. California\":  \"US/Pacific\",\n",
    "        \"Sydney\":  \"Australia/Sydney\",\n",
    "        \"Oregon\":  \"US/Pacific\",\n",
    "        \"GovCloud\":  \"US/Pacific\",\n",
    "        \"London\":  \"Europe/London\",\n",
    "        \"Ohio\":  \"EST\",\n",
    "        \"Sao Paulo\":  \"America/Sao_Paulo\",\n",
    "        \"Tokyo\":  \"Asia/Tokyo\",\n",
    "        \"Mumbai\":  \"Asia/Kolkata\",\n",
    "        \"Singapore\":  \"Asia/Singapore\",\n",
    "        \"Seoul\":  \"Asia/Seoul\",\n",
    "        \"Frankfurt\":  \"Europe/Berlin\",\n",
    "        \"Paris\":  \"Europe/Paris\",\n",
    "        \"US-West\":  \"US/Pacific\",\n",
    "        \"East US\":  \"EST\",\n",
    "        \"global\":  \"GMT\",\n",
    "        \"RCA – Resources using IPv4 addressing – West and South India\":  \"Asia/Kolkata\",\n",
    "        \"West Europe\":  \"Europe/Amsterdam\",\n",
    "        \"West US\":  \"US/Pacific\",\n",
    "        \"Australia East\":  \"Australia/Sydney\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"North Central US\":  \"America/Chicago\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"North Europe and West Europe\":  \"Europe/Berlin\",\n",
    "        \"UK West\":  \"Europe/London\",\n",
    "        \"South Central US\":  \"US/Central\",\n",
    "        \"RCA – Storage – West US\":  \"US/Pacific\",\n",
    "        \"West India and South India\":  \"Asia/Kolkata\",\n",
    "        \"Latency between North Europe and North America\":  \"GMT\",\n",
    "        \"France Central\":  \"Europe/Paris\",\n",
    "        \"East Asia\":  \"Asia/Hong_Kong\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"Australia Southeast\":  \"Australia/Melbourne\",  # based on https://azure.microsoft.com/en-us/global-infrastructure/regions/\n",
    "        \"Korea South\":  \"Asia/Seoul\",\n",
    "        \"Southeast Asia\":  \"Asia/Singapore\",\n",
    "        \"West Europe and North Europe\":  \"Europe/Berlin\",\n",
    "        \"Latency and Slow I/O issues in East US\":  \"EST\",\n",
    "        \"Networking in West US\":  \"US/Pacific\",\n",
    "        \"UK South\":  \"Europe/London\",\n",
    "        \"West US 2\":  \"US/Central\",\n",
    "        \"East US and West US\":  \"US/Central\",\n",
    "        \"UK South and UK West\":  \"Europe/London\",\n",
    "        \"North Europe\":  \"Europe/Berlin\",\n",
    "        \"UK South/UK West\":  \"Europe/London\",\n",
    "        \"West Central US\":  \"US/Central\",\n",
    "        \"West Europe | Mitigated\":  \"Europe/Amsterdam\",\n",
    "        \"Data Processing in East US\":  \"EST\",\n",
    "        \"Australia East/Southeast\":  \"Australia/Melbourne\",\n",
    "        \"Canada Central\":  \"Canada/Central\",\n",
    "        \"Japan East\":  \"Japan\",\n",
    "        \"Multiple Azure Services impacted in West Europe\":  \"Europe/Amsterdam\",\n",
    "        \"Service availability issue in North Europe\":  \"Europe/Berlin\",\n",
    "        \"Service Availability Issue in North Europe\":  \"Europe/Berlin\",\n",
    "        \"South East Asia\":  \"Asia/Singapore\",\n",
    "    }\n",
    "    try:\n",
    "        timezone_diff = pytz.timezone(offset[row['location']])\n",
    "        localized_event_start_time = row['event_start_time'].tz_convert(timezone_diff)\n",
    "        weekday_int = localized_event_start_time.dayofweek\n",
    "        hour = localized_event_start_time.hour\n",
    "        row['hour_of_week'] = (weekday_int+1)*24+hour\n",
    "    except KeyError:\n",
    "        # TODO: had some issue with Canada\n",
    "        pass\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_parquet(\"../data/classified.parquet\")\n",
    "original = pd.read_parquet(\"../data/outages.parquet\")\n",
    "dfj = df.join(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj['duration_min'] = (dfj.event_end_time - dfj.event_start_time)/60.0\n",
    "dfj[\"event_start_time\"] = pd.to_datetime(dfj[\"event_start_time\"], unit=\"s\", utc=True)\n",
    "dfj[\"event_end_time\"] = pd.to_datetime(dfj[\"event_end_time\"], unit=\"s\", utc=True)\n",
    "dfj = dfj.apply(add_hour_of_week, axis='columns')\n",
    "dfj.drop(labels=['event_start_time', 'event_end_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_emptys(cell):\n",
    "    from numpy import ndarray\n",
    "    if type(cell) == ndarray and len(cell) == 0:\n",
    "        return ['not provided']\n",
    "    elif type(cell) == str and not bool(cell):\n",
    "        return 'not provided'\n",
    "    \n",
    "    return cell\n",
    "\n",
    "dfj = dfj.applymap(clean_emptys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed:\n",
      "- AWS: 133\n",
      "- GCP: 22\n"
     ]
    }
   ],
   "source": [
    "def deduplicate(df):\n",
    "    known_dupe_idxs = [928]\n",
    "    df = df.drop(known_dupe_idxs, axis='index')\n",
    "    \n",
    "    df['cutdesc'] = df.description.astype('str').apply(lambda x: x[25:])\n",
    "    dfnew = df.drop_duplicates(['cutdesc']).drop(labels=['cutdesc'], axis='columns')\n",
    "    \n",
    "    removed_vendors = df.loc[df.index.difference(dfnew.index)].vendor.value_counts()\n",
    "    print(\"Removed:\")\n",
    "    for vd, cnt in removed_vendors.iteritems():\n",
    "        print(f'- {vd}: {cnt}')\n",
    "    \n",
    "    return dfnew\n",
    "\n",
    "dfj = deduplicate(dfj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['affected', 'cause', 'description', 'duplicate', 'duration',\n",
       "       'duration_min', 'first_notification', 'half_desc', 'hour_of_week',\n",
       "       'last_notification', 'location', 'monitor', 'org_type', 'range',\n",
       "       'service_id', 'service_name', 'services', 'severity', 'status', 'users',\n",
       "       'vendor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj = dfj.astype({'affected': 'object',\n",
    "                  'cause': 'object',\n",
    "                  'description': 'str',\n",
    "                  'duplicate': 'bool',\n",
    "                  'duration': 'str',\n",
    "                  'duration_min': 'float',\n",
    "                  'first_notification': 'Int64',\n",
    "                  'half_desc': 'str',\n",
    "                  'hour_of_week': 'Int32',\n",
    "                  'last_notification': 'Int64',\n",
    "                  'location': 'str',\n",
    "                  'monitor': 'str',\n",
    "                  'org_type': 'str',\n",
    "                  'range': 'str',\n",
    "                  'service_id': 'str',\n",
    "                  'service_name': 'str',\n",
    "                  'services': 'str',\n",
    "                  'severity': 'object',\n",
    "                  'status': 'float',\n",
    "                  'users': 'str'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfj.to_parquet(\"../data/preprocessed.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
